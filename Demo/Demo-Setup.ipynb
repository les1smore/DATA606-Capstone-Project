{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.11.0-py2.py3-none-any.whl (15.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.1.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.11.0 tenacity-8.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from xgboost import XGBClassifier "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('/Users/leslie/Desktop/DATA606/diabetes_B (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good Health                              0\n",
       "Health Coverage                          0\n",
       "High Blood Pressure                      0\n",
       "High Cholesterol                         0\n",
       "CHD-MI                                   0\n",
       "Asthma Status                            0\n",
       "Diagnosed Arthritis                      0\n",
       "Race/Ethnicity                           0\n",
       "BMI Category                             0\n",
       "Overweight/Obese                         0\n",
       "Education Level                          0\n",
       "Income Category                          0\n",
       "Smoker Status                            0\n",
       "Heavy Drinker                            0\n",
       "Consume Fruit                            0\n",
       "Consume Veggie                           0\n",
       "Physical Activity Categories             0\n",
       "Aerobic Reccomendations                  0\n",
       "Muscle Strengthening Recommendation      0\n",
       "Good Physical Health                     0\n",
       "Good Mental Health                       0\n",
       "High Cost of Medical                     0\n",
       "Routine Check-up                         0\n",
       "Taking BP Meds                           0\n",
       "Skin Cancer                              0\n",
       "Other Cancer                             0\n",
       "Chronic Obstructive Pulmonary Disease    0\n",
       "Depressive Disorder                      0\n",
       "Kidney Disease                           0\n",
       "Have_Diabetes                            0\n",
       "Pre-diabetic                             0\n",
       "Taking Insulin                           0\n",
       "Have Cateracts                           0\n",
       "Glaucoma                                 0\n",
       "macular degeneration                     0\n",
       "Memory Loss                              0\n",
       "Watching sodium                          0\n",
       "Sleep Disordered Breathing               0\n",
       "Trouble sleeping                         0\n",
       "Sex                                      0\n",
       "Age                                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deal with missing values\n",
    "# Select rows where our target is not NaN\n",
    "data = data[data['Have_Diabetes'].notna()]\n",
    "\n",
    "# Fill in missing values of other columns with mean \n",
    "col_mean = np.ceil(data.mean())\n",
    "\n",
    "data.fillna(col_mean, inplace=True)\n",
    "\n",
    "# Check if it works\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows =  9988\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "#check for row duplication\n",
    "dupes= data[data.duplicated()]\n",
    "print('number of rows = ', len(dupes))\n",
    "dupes.head()\n",
    "\n",
    "data.drop_duplicates(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_features = ['Pre-diabetic', 'Taking Insulin','High Blood Pressure', 'BMI Category', 'Age','Good Health', 'Routine Check-up', 'High Cholesterol', 'Income Category', 'CHD-MI','Kidney Disease', 'Race/Ethnicity','Taking BP Meds', 'Heavy Drinker','Have_Diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns of great importance to prediction based on previous work\n",
    "new_df = data.loc[:, key_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in column 'Pre-diabetic': [0. 1. 2. 7. 9.]\n",
      "Unique values in column 'Taking Insulin': [1. 0. 9.]\n",
      "Unique values in column 'High Blood Pressure': [1. 0.]\n",
      "Unique values in column 'BMI Category': [4. 3. 2. 1.]\n",
      "Unique values in column 'Age': [ 9.  7. 11. 13. 10. 12.  8.  4.  6.  2.  3.  5.  1.]\n",
      "Unique values in column 'Good Health': [0. 1.]\n",
      "Unique values in column 'Routine Check-up': [1. 4. 3. 2. 0. 7. 9.]\n",
      "Unique values in column 'High Cholesterol': [1. 0.]\n",
      "Unique values in column 'Income Category': [2. 1. 5. 4. 3.]\n",
      "Unique values in column 'CHD-MI': [0. 1.]\n",
      "Unique values in column 'Kidney Disease': [0. 7. 1. 9.]\n",
      "Unique values in column 'Race/Ethnicity': [1. 7. 2. 3. 6. 4. 8. 5.]\n",
      "Unique values in column 'Taking BP Meds': [1. 0. 7. 9.]\n",
      "Unique values in column 'Heavy Drinker': [0. 9. 1.]\n",
      "Unique values in column 'Have_Diabetes': [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for col in new_df.columns:\n",
    "          print(f\"Unique values in column '{col}': {new_df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('./data_nonull.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and Y\n",
    "X = data.drop('Have_Diabetes', axis=1)\n",
    "y = data.Have_Diabetes\n",
    "\n",
    "# Split the train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.3, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(325841, 40) (228088, 40) (97753, 40)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    283909\n",
       "1.0     41932\n",
       "Name: Have_Diabetes, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_size = data['Have_Diabetes'].value_counts()\n",
    "class_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Diabetes:283909 and Having Diabtes:41932\n",
      "The estimated sale_pos_weight is 6.770700181245827\n"
     ]
    }
   ],
   "source": [
    "print(f'No Diabetes:{class_size[0]} and Having Diabtes:{class_size[1]}')\n",
    "scale_pos_weight = class_size[0]/class_size[1] # total negative examples / total positive examples\n",
    "print(f'The estimated sale_pos_weight is {scale_pos_weight}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=1, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=152,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=1, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=152,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=1, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=152,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the classifier again with previously tuned hyperparameters\n",
    "xgb_tuned = XGBClassifier(min_child_weight = 1,\n",
    "                             max_depth=1,\n",
    "                             n_estimators=152, \n",
    "                             scale_pos_weight = scale_pos_weight)  # Handle the class imbalance\n",
    "\n",
    "xgb_tuned.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the threshold we trained before for higher recall\n",
    "predicted_xgb = xgb_tuned.predict(X_test, ntree_limit=np.argmax(xgb_tuned.predict_proba(X_test)[:,1] >= 0.0935))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the two performance evaluation functions\n",
    "def get_scores(y_test, y_pred, model):\n",
    "        \"\"\"\n",
    "        Build a data frame containing all classification metrics and confusion matrix results.\n",
    "        \"\"\"\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel() # Convert to 1-D array\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        specificity = tn/(tn+fp)\n",
    "\n",
    "        all_scores = {'Model Name':[model], 'Precision':[precision],\n",
    "                    'Recall':[recall], 'F1 Score':[f1],\n",
    "                    'Specificity':[specificity], 'Accuracy':[acc]}\n",
    "        df_score = pd.DataFrame(data=all_scores)\n",
    "        return df_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost, optimized t</td>\n",
       "      <td>0.417823</td>\n",
       "      <td>0.811367</td>\n",
       "      <td>0.551596</td>\n",
       "      <td>0.833022</td>\n",
       "      <td>0.830235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model Name  Precision    Recall  F1 Score  Specificity  Accuracy\n",
       "0  XGBoost, optimized t   0.417823  0.811367  0.551596     0.833022  0.830235"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scores(y_test, predicted_xgb, 'XGBoost, optimized t')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Predictive System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_data = data.iloc[0].apply(lambda x: str(x)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 0]\n",
      "The respondent is not predicted diabetic\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the first row data as an input example\n",
    "row_data = data.iloc[0,:-1].apply(lambda x: str(x)).tolist()\n",
    "\n",
    "# changing the input_data to numpy array\n",
    "input_data_as_numpy_array = np.asarray(row_data)\n",
    "\n",
    "# reshape the array as we are predicting for one instance\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
    "\n",
    "prediction = xgb_tuned.predict(X_test, ntree_limit=np.argmax(xgb_tuned.predict_proba(X_test)[:,1] >= 0.0935))\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0] == 0):\n",
    "  print('The respondent is not predicted diabetic')\n",
    "else:\n",
    "  print('The repondent is predicted diabetic')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'diabetes_model.sav'\n",
    "pickle.dump(xgb_tuned, open(filename, 'wb'))\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = pickle.load(open('diabetes_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 0]\n",
      "The person is not diabetic\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the first row data as an input example\n",
    "row_data = data.iloc[0,:-1].apply(lambda x: str(x)).tolist()\n",
    "\n",
    "# changing the input_data to numpy array\n",
    "input_data_as_numpy_array = np.asarray(row_data)\n",
    "\n",
    "# reshape the array as we are predicting for one instance\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
    "\n",
    "prediction = loaded_model.predict(X_test, ntree_limit=np.argmax(xgb_tuned.predict_proba(X_test)[:,1] >= 0.0935))\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0] == 0):\n",
    "  print('The person is not diabetic')\n",
    "else:\n",
    "  print('The person is diabetic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
